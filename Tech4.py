# -*- coding: utf-8 -*-
"""TechChallenge_Fase_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QoBl0jRKBrs1XlB14pZpSsGhOjBF1iKF

# Tech Challenge Fase 4
# Data Analytics FIAP - 02/2025
# Alison Sérgio de Amarins Germano - RM 357521

*Ambiente de desenvolvimento utilizado foi o VS CODE

**1. Desenvolver um modelo preditivo com dados da Cotação do preço de barril de petróleo para criar uma série temporal e prever diariamente o fechamento.**

**1. Instalando Bibliotecas**
"""

#! pip install matplotlib
#! pip install numpy
#! pip install pandas
#! pip install statsmodels
#! pip install xgboost
#! pip install yfinance
#! pip install pmdarima
#! pip install prophet
#! pip install sklearn
#!pip install statsforecast

# Bibliotecas utilizadas
#import matplotlib
#import numpy
#import pandas
#import statsmodels
#import xgboost
#import yfinance
#import pmdarima
#import prophet
#import sklearn
#import StatsForecast

# Importando e Aplicando o álias a cada biblioteca
import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import statsmodels.api as sm
import xgboost as xgb
import yfinance as yf
import pmdarima as pm
from prophet import Prophet
from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    mean_absolute_percentage_error,
)
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsforecast import StatsForecast
from statsforecast.models import Naive, SeasonalNaive, SeasonalWindowAverage, AutoARIMA
from statsforecast.utils import ConformalIntervals
from prophet import Prophet
from statsmodels.graphics.gofplots import qqplot
from scipy.stats import shapiro
from statsmodels.tsa.statespace.sarimax import SARIMAX
import seaborn as sns

# Ignorar avisos específicos emitidos pelo Pandas tipo SettingWithCopyWarning
import warnings
from pandas.errors import SettingWithCopyWarning

warnings.simplefilter(action="ignore", category=SettingWithCopyWarning)
warnings.simplefilter(action="ignore", category=FutureWarning)
warnings.simplefilter(action="ignore", category=UserWarning)
warnings.simplefilter(action="ignore")

st.write("# Fase 4")
st.write("# Tech Challenge-Data Analytics",)
st.write('<b><span style="font-size: 20px;">Alison Sérgio de Amarins Germano - RM 357521</b>', unsafe_allow_html=True) 

#"""**1**.Acessando a base de dados"""
# Títulos
#ticker = "^BVSP"
ticker = "BZ=F"
data_principal = yf.download(ticker, start="2014-09-19", end="2024-09-20")

#data_principal = yf.Ticker(ticker)

# Resetar o índice para mover o DatetimeIndex para uma coluna
data_principal2 = data_principal.copy()
data_principal2.reset_index(inplace=True)
#print(data_principal2)
#print(data_principal2.columns)


# Selecionar e renomear as colunas para a nova estrutura
df_novo = pd.DataFrame({
    ('Price', 'ds'): data_principal2['Date'],  # A coluna de datas
    ('Price', 'y'): data_principal2['Close'],  # A coluna de fechamento
    ('Price', 'unique_id'): ticker  # Adicionar o ticker como valor fixo
})
df_novo2 = df_novo.copy()

# Exibir o resultado
#print(df_novo.head())

# Analisando as informacoes do DataFrame principal
#data_principal.info()

#data_principal.head()

# Segmentando o DataFrame
dados = data_principal[["Open", "Close"]]
dados.dropna(inplace=True)
dados.reset_index(inplace=True)
# Análise Exploratória
#dados.info()

#dados.head()

#dados.tail()

# Analisando a dimensão
#dados.shape

# Pontuação Mínima
#st.write("Preço Mínimo: ", dados["Close"].min())

# Pontuação Máxima
#st.write("Preço Máximo: ", dados["Close"].max())

# Ver se existe valores nulos
dados.isnull().sum()

# Verificar valores duplicados
dados.duplicated().sum()

#Analisando informações básicas de matemáticas, como média, valor mínimo e máximo, desvio padrão e quartil (que representa uma porcentagem de amostra dos dados).
dados.describe()
# Título da aplicação no navegador
st.title("Visualização dos Dados Históricos")
# Adicionando descrição
st.write("Gráfico de evolução do fechamento dos dados históricos.")
# Criando a visualização com matplotlib
fig, ax = plt.subplots(figsize=(12, 8))
ax.plot(dados["Date"], dados["Close"], label="Evolução Fechamento")
ax.set_title("Dados Históricos")
ax.set_xlabel("Período")
ax.set_ylabel("Quantidade de Pontos")
ax.legend()
# Renderizar o gráfico no navegador usando Streamlit
st.pyplot(fig)
#Verificar se existem dados no Dataframe
st.write("Exibindo os últimos valores de abertura e fechamento")
st.write(dados.head())  # Mostra as primeiras linhas do DataFrame
print(dados.columns) # Mostra os nomes das colunas

"""**Analisando Outliers**"""

dados2 = dados.copy()
# Removendo o MultiIndex das colunas
dados2.columns = ['Date', 'Open', 'Close']

# Conferindo a estrutura do DataFrame após o ajuste
#print(dados2.head())


# Criando o boxplot
#sns.set(style="whitegrid")
#fig, axes = plt.subplots(figsize=(12, 8))
#sns.boxplot(x="Close", data=dados2)
#axes.set_title("Boxplot")
#plt.show()
# Título do aplicativo no navegador
st.title("Visualização de Boxplot")
# Adicionando uma descrição
st.write("Este gráfico mostra a distribuição dos valores de fechamento (Close).")
# Criando o boxplot com Seaborn
sns.set(style="whitegrid")
fig, ax = plt.subplots(figsize=(12, 8))
sns.boxplot(x="Close", data=dados2, ax=ax)
ax.set_title("Boxplot")
# Renderizando no Streamlit
st.pyplot(fig)

"""**Mesclar o Gráfico Violin com Box Plot**"""
#Mesclar os dois tipos de gráficos analisar valores discrepantes, caso exista
#fig, ax = plt.subplots(figsize=(12,8))
#Configurando o violin plot primeiramente
#sns.violinplot(x="Close", data=dados2, ax=ax, color="lightgray")
#Por baixo criar um boxplot
#sns.boxplot(x="Close", data=dados2, ax=ax, whis=1.5, color="darkblue")
#ax.set_title("Visualização Box Plot e Violin Plot")
#Mostrando o gráfico
#plt.show()
# Título da aplicação no navegador
st.title("Box Plot e Violin Plot")
# Descrição
st.write("Este gráfico mescla um **Violin Plot** e um **Box Plot** para identificar valores discrepantes.")
# Criando o gráfico
fig, ax = plt.subplots(figsize=(12, 8))
# Violin Plot (em cinza claro)
sns.violinplot(x="Close", data=dados2, ax=ax, color="lightgray")
# Box Plot (em azul escuro)
sns.boxplot(x="Close", data=dados2, ax=ax, whis=1.5, color="darkblue")
# Adicionando o título
ax.set_title("Visualização Box Plot e Violin Plot")
# Exibindo o gráfico no Streamlit
st.pyplot(fig)
"""Observa-se que não existem dados discrepantes.

**Histograma dos Pontos de Fechamento**
"""

import matplotlib.pyplot as plt

# Plotar o histograma da variável 'Close'
#plt.hist(dados["Close"], bins=20, edgecolor="black")
#plt.title("Histograma dos Pontos de Fechamento")
#plt.xlabel("Pontos de Fechamento")
#plt.ylabel("Frequência")
#plt.figure(figsize=(12,8))
#plt.show()
# Título da aplicação no navegador
st.title("Histograma dos Pontos de Fechamento")

# Descrição
st.write("Este gráfico mostra o histograma dos pontos de fechamento ('Close').")
# Criando o histograma
fig, ax = plt.subplots(figsize=(12, 8))
# Plotando o histograma
ax.hist(dados["Close"], bins=20, edgecolor="black")
# Adicionando título e rótulos aos eixos
ax.set_title("Histograma dos Pontos de Fechamento")
ax.set_xlabel("Pontos de Fechamento")
ax.set_ylabel("Frequência")

# Exibindo o gráfico no Streamlit
st.pyplot(fig)
"""***Aplicando a Amplitude  nos Valores***"""

dadosRaiz = dados.copy()

dadosRaiz["Close_Raiz"] = np.sqrt(dadosRaiz["Close"])
#plt.hist(dadosRaiz["Close_Raiz"], bins=20, edgecolor="black")
#plt.title("Histograma dos Pontos de Fechamento Ampliado")
#plt.xlabel("Pontos de Fechamento Ampliado")
#plt.ylabel("Frequência")
#plt.figure(figsize=(12,8))
#plt.show()
# Título da aplicação no navegador
st.title("Histograma dos Pontos de Fechamento Ampliado")
# Descrição
st.write("Este gráfico mostra o histograma dos pontos de fechamento ampliado ('Close_Raiz').")
# Criando o histograma
fig, ax = plt.subplots(figsize=(12, 8))
# Plotando o histograma
ax.hist(dadosRaiz["Close_Raiz"], bins=20, edgecolor="black")
# Adicionando título e rótulos aos eixos
ax.set_title("Histograma dos Pontos de Fechamento Ampliado")
ax.set_xlabel("Pontos de Fechamento Ampliado")
ax.set_ylabel("Frequência")
# Exibindo o gráfico no Streamlit
st.pyplot(fig)



"""**Gráfico de Pontos de Abertura e Fechamento**"""

import matplotlib.pyplot as plt

# Plotar a variação de Open e Close ao longo do tempo
data_principal.reset_index(inplace=True)
#plt.figure(figsize=(12,8))
#plt.plot(data_principal["Date"], data_principal["Open"], label="Open",color='red',linewidth=0.3)
#plt.plot(data_principal["Date"], data_principal["Close"], label="Close",color='blue',linewidth=0.2)
#plt.title("Open vs Close")
#plt.xlabel("Data")
#plt.ylabel("Pontos")
#plt.legend()
#plt.show()
# Título da aplicação no navegador
st.title("Gráfico Open vs Close")

# Descrição
st.write("Este gráfico mostra a comparação entre os pontos de abertura ('Open') e fechamento ('Close').")
# Criando o gráfico
fig, ax = plt.subplots(figsize=(12, 8))
# Plotando os dados de "Open"
ax.plot(data_principal["Date"], data_principal["Open"], label="Open", color='red', linewidth=0.3)
# Plotando os dados de "Close"
ax.plot(data_principal["Date"], data_principal["Close"], label="Close", color='blue', linewidth=0.2)
# Adicionando título e rótulos aos eixos
ax.set_title("Open vs Close")
ax.set_xlabel("Data")
ax.set_ylabel("Pontos")
# Adicionando a legenda
ax.legend()
# Exibindo o gráfico no Streamlit
st.pyplot(fig)


"""**Identificando o Padrão da Série Temporal**"""

result = seasonal_decompose(dados["Close"], model="multiplicative", period=252)
result.seasonal.iloc[:252].plot(figsize=(12, 8))

"""**Realizando a decomposição de série temporal para separar os componentes mais simples e interpretáveis, com o objetivo de analisar o comportamento e melhorar a qualidade dos modelo preditivo.**"""

# Decomposição da série temporal
#dados.info()
# Tendência - Direção
# Sazonalidade - recorrência das oscilações
# Resíduo - o q sobra do sinal

df = data_principal[["Date", "Close"]]
df.set_index("Date",inplace=True)
#df.info()
df.index = pd.to_datetime(df.index)
df = df.asfreq('D')
df['Close'] = df['Close'].ffill()

resultados = seasonal_decompose(df,  period=252)

#fig,(ax1,ax2,ax3,ax4) = plt.subplots(4,1,figsize=(12,8))
#resultados.observed.plot(ax=ax1, label='Observed' )
#ax1.legend()
#resultados.trend.plot(ax=ax2, label='Trend')
#ax2.legend()
#resultados.seasonal.plot(ax=ax3, label='Seasonal')
#ax3.legend()
#resultados.resid.plot(ax=ax4, label='Resid')
#ax4.legend()
#plt.tight_layout()
#plt.show()
# Título da aplicação no navegador
st.title("Decomposição de Séries Temporais")

# Descrição
st.write("Este gráfico mostra a decomposição da série temporal em componentes observados, tendência, sazonalidade e resíduos.")

# Criando os subgráficos
fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 8))
# Plotando o componente 'Observed'
resultados.observed.plot(ax=ax1, label='Observed')
ax1.legend()
# Plotando o componente 'Trend'
resultados.trend.plot(ax=ax2, label='Trend')
ax2.legend()
# Plotando o componente 'Seasonal'
resultados.seasonal.plot(ax=ax3, label='Seasonal')
ax3.legend()
# Plotando o componente 'Resid'
resultados.resid.plot(ax=ax4, label='Resid')
ax4.legend()
# Ajustando o layout
plt.tight_layout()
# Exibindo o gráfico no Streamlit
st.pyplot(fig)


"""**Distribuição dos Resíduos com Histograma e Teste de Normalidade.**"""

# Criando novos gráficos para os resíduos: histograma e teste de normalidade
#fig, (ax5, ax6) = plt.subplots(2, 1, figsize=(12, 8))
# Plotando o histograma dos resíduos
#sns.histplot(resultados.resid.dropna(), kde=True, ax=ax5)
#ax5.set_title('Histograma dos Resíduos')
# Teste de normalidade: QQ plot
#qqplot(resultados.resid.dropna(), line='s', ax=ax6)
#ax6.set_title('Normalidade')
#plt.tight_layout()
#plt.show()
# Título da aplicação no navegador
st.title("Análise de Resíduos")
# Descrição
st.write("Este gráfico mostra o histograma dos resíduos e o teste de normalidade com o QQ plot.")
# Criando os subgráficos
fig, (ax5, ax6) = plt.subplots(2, 1, figsize=(12, 8))
# Plotando o histograma dos resíduos
sns.histplot(resultados.resid.dropna(), kde=True, ax=ax5)
ax5.set_title('Histograma dos Resíduos')
# Teste de normalidade: QQ plot
qqplot(resultados.resid.dropna(), line='s', ax=ax6)
ax6.set_title('Normalidade')
# Ajustando o layout
plt.tight_layout()
# Exibindo o gráfico no Streamlit
st.pyplot(fig)



# Teste Shapiro-Wilk para normalidade
stat, p_value = shapiro(resultados.resid.dropna())
print(f'Shapiro-Wilk Teste de Normalidade: p-value = {p_value:.4f}')

"""**O p-value = 0.0000 logo pode-se concluir que os resíduos do modelo não seguem uma distribuição normal.**

**Identificar se é uma Série Estacionaria**
"""

# Estacionária ou não estacionária

# ADF - Augmented Dickey-Fuller

# H0 - Hipótese Nula (não é estacionária)
# H1 ou HA (Depende da abordagem) - Hipótese Alternativa (rejeição da hipótese nula)

# p -value = 0.05 (5%), então rejeitamos H0 com um nível de confiança de 95%

sns.set_style('darkgrid')

x = df.Close.values

result = adfuller(x)

print("Teste ADF")
print(f"Teste Estatístico: {result[0]}")
print(f"P-Value: {result[1]}")
print("Valores críticos:")

for key, value in result[4].items():
  print(f"\t{key}: {value}")

"""P-Value: 0.85, Teste Estatístico: -0.6 maior que os valores críticos, indicando que não é uma série estacionária, então fazer a transformação para estacionária, mas antes um pouco mais de análise gráfica."""

# Plotando a linha da média móvel em cima da série
# 252 dias úteis
ma = df.rolling(252).mean()

#f, ax = plt.subplots()
#df.plot(ax=ax, legend=False)
#ma.plot(ax=ax, legend=False, color='r')
#plt.tight_layout()
#plt.figure(figsize=(12,8))
#plt.show()
# Título da aplicação no navegador
st.title("Visualização de Séries Temporais")

# Criando a figura e o eixo
fig, ax = plt.subplots(figsize=(12, 8))
# Plotando os dados
df.plot(ax=ax, legend=False)
ma.plot(ax=ax, legend=False, color='r')
# Ajustando o layout
plt.tight_layout()
# Exibindo o gráfico no Streamlit
st.pyplot(fig)



"""Aplicando a função logarítimica Numpy para suavizar a série realizando uma transformação da escala tentanto ver se fica mais estacionária."""

df_log = np.log(df)
ma_log = df_log.rolling(252).mean()

#f, ax = plt.subplots()
#df_log.plot(ax=ax, legend=False)
#ma_log.plot(ax=ax, legend=False, color='r')
#plt.tight_layout()
#plt.figure(figsize=(12,8))
#plt.show()
# Criando a figura e o eixo
fig, ax = plt.subplots(figsize=(12, 8))
# Plotando os dados
df_log.plot(ax=ax, legend=False)
ma_log.plot(ax=ax, legend=False, color='r')
# Ajustando o layout
plt.tight_layout()
# Exibindo o gráfico no Streamlit
st.pyplot(fig)


"""Subtraindo a média móvel e utilizar 252 dias."""

df_s = (df_log - ma_log).dropna()

ma_s = df_s.rolling(252).mean()

std = df_s.rolling(252).std()

#f, ax = plt.subplots()
#df_s.plot(ax=ax, legend=False)
# Média
#ma_s.plot(ax=ax, legend=False, color='r')
# Desvio Padrão
#std.plot(ax=ax, legend=False, color='g')
#plt.figure(figsize=(12,8))
#plt.tight_layout()
# Criando a figura e o eixo
fig, ax = plt.subplots(figsize=(12, 8))
# Plotando os dados
df_s.plot(ax=ax, legend=False, label="Série Original")
ma_s.plot(ax=ax, legend=False, color='r', label="Média Móvel")
std.plot(ax=ax, legend=False, color='g', label="Desvio Padrão")
# Ajustando o layout
plt.tight_layout()
# Exibindo o gráfico no Streamlit
st.pyplot(fig)


"""**Realizar o Teste ADF Novamente.**"""
x_s = df_s.Close.values
result_s = adfuller(x_s)
print("Teste ADF")
print(f"Teste Estatístico: {result_s[0]}")
print(f"P-Value: {result_s[1]}")
print("Valores críticos:")

for key, value in result_s[4].items():
  print(f"\t{key}: {value}")

"""P-Value: 3. exponencial que indica próximo a Zero, Teste Estatístico: -4 sendo menor que os valores críticos, indicando que a série se aproximou muito de uma estacionária.

**Aplicando a primeira diferenciação e o teste ADF**
"""

df_diff = df_s.diff(1)
ma_diff = df_diff.rolling(252).mean()
std_diff = df_diff.rolling(252).std()

#f, ax = plt.subplots()
#df_diff.plot(ax=ax, legend=False)
#ma_diff.plot(ax=ax, legend=False, color='r')
#std_diff.plot(ax=ax, legend=False, color='g')
#plt.figure(figsize=(12,8))
#plt.tight_layout()
# Criando a figura
fig, ax = plt.subplots(figsize=(12, 8))
# Plotando os dados
df_diff.plot(ax=ax, legend=False, label="Série Diferenciada")
ma_diff.plot(ax=ax, legend=False, color='r', label="Média Móvel")
std_diff.plot(ax=ax, legend=False, color='g', label="Desvio Padrão")
# Ajustando o layout
plt.tight_layout()
# Exibindo o gráfico no Streamlit
st.pyplot(fig)




x_diff = df_diff.Close.dropna().values
result_diff = adfuller(x_diff)
print("Teste ADF")
print(f"Teste Estatístico: {result_diff[0]}")
print(f"P-Value: {result_diff[1]}")
print("Valores críticos:")

for key, value in result_diff[4].items():
  print(f"\t{key}: {value}")

"""**P-Value 0 , a série está zerada, então se transformou em estacionária.**

**Aplicando a Função de Autocorrelação ACF e Autocorrelação Parcial PACF e Analisando**
"""

# Utilizando o DF suavizado
df_diff.info()

"""**Realizando a análise de Auto Correlação para 21 dias.**"""

# nlags esta em dias podendo ser ajustado
lag_acf = acf(df_diff.Close.dropna(), nlags=21)
lag_pacf = pacf(df_diff.Close.dropna(), nlags=21)

# Observando as diferenças ACF e PACF
# Valor -1 porquê a série foi diferenciada uma vez.
# ACF
#plt.plot(lag_acf)
#plt.axhline(y=0,linestyle='--',color='gray')
#plt.axhline(y=-1.96/np.sqrt(len(df_diff.Close-1)),linestyle='--',color='gray', linewidth=0.5)
#plt.axhline(y=0,linestyle='--',color='gray', linewidth=0.5)
#plt.axhline(y=1.96/np.sqrt(len(df_diff.Close-1)),linestyle='--',color='gray', linewidth=0.5)
#plt.title('ACF')
#plt.show()
# PACF
#plt.plot(lag_pacf)
#plt.axhline(y=0,linestyle='--',color='gray')
#plt.axhline(y=-1.96/np.sqrt(len(df_diff.Close.dropna()-1)),linestyle='--',color='gray', linewidth=0.5)
#plt.axhline(y=0,linestyle='--',color='gray', linewidth=0.5)
#plt.axhline(y=1.96/np.sqrt(len(df_diff.Close.dropna()-1)),linestyle='--',color='gray', linewidth=0.5)
#plt.title('PACF')
#plt.show()

# Título da aplicação
st.title("Análise de ACF e PACF")

# Simulação de dados (substitua pelo seu dataset real)
#df_diff = pd.DataFrame({"Close": np.random.rand(100) * 100})  # Exemplo fictício
#lag_acf = np.correlate(df_diff["Close"], df_diff["Close"], mode='full')[-100:]  # Exemplo
# lag_pacf = np.correlate(df_diff["Close"], df_diff["Close"], mode='full')[-100:]  # Exemplo

# Criando a figura para ACF
fig_acf, ax_acf = plt.subplots(figsize=(12, 6))
ax_acf.plot(lag_acf, label="ACF")
ax_acf.axhline(y=0, linestyle='--', color='gray', linewidth=0.5)
ax_acf.axhline(y=-1.96 / np.sqrt(len(df_diff.Close) - 1), linestyle='--', color='gray', linewidth=0.5)
ax_acf.axhline(y=1.96 / np.sqrt(len(df_diff.Close) - 1), linestyle='--', color='gray', linewidth=0.5)
ax_acf.set_title("Autocorrelation Function (ACF)")
st.pyplot(fig_acf)

# Criando a figura para PACF
fig_pacf, ax_pacf = plt.subplots(figsize=(12, 6))
ax_pacf.plot(lag_pacf, label="PACF")
ax_pacf.axhline(y=0, linestyle='--', color='gray', linewidth=0.5)
ax_pacf.axhline(y=-1.96 / np.sqrt(len(df_diff.Close.dropna()) - 1), linestyle='--', color='gray', linewidth=0.5)
ax_pacf.axhline(y=1.96 / np.sqrt(len(df_diff.Close.dropna()) - 1), linestyle='--', color='gray', linewidth=0.5)
ax_pacf.set_title("Partial Autocorrelation Function (PACF)")
st.pyplot(fig_pacf)


"""Ilustrando melhor a identificação dos valores x e y"""

from IPython.display import Image

# Valor de x
#Image('/content/acf_x.jpg')
st.image("acf_x.jpg", caption='ACF')
#Image('/content/pacf_y.jpg')
st.image("pacf_y.jpg", caption='PACF')

#Analisando o quanto o período de 21 dias está relacionado com outro
# ACF Relação Direta e Indireta
#plot_acf(df.loc[df.index >= (df.index.max() - pd.Timedelta(days=21)), 'Close'])
# PACF Relação apenas direta
#plot_pacf(df.loc[df.index >= (df.index.max() - pd.Timedelta(days=21)), 'Close'])
#plt.show()
# Filtrar os últimos 21 dias
df_filtered = df.loc[df.index >= (df.index.max() - pd.Timedelta(days=21)), 'Close']
# Criando a figura para ACF
fig_acf, ax_acf = plt.subplots(figsize=(12, 6))
plot_acf(df_filtered, ax=ax_acf)
ax_acf.set_title("Autocorrelation Function (ACF) - Últimos 21 Dias")
st.pyplot(fig_acf)
# Criando a figura para PACF
fig_pacf, ax_pacf = plt.subplots(figsize=(12, 6))
plot_pacf(df_filtered, ax=ax_pacf)
ax_pacf.set_title("Partial Autocorrelation Function (PACF) - Últimos 21 Dias")
st.pyplot(fig_pacf)

# Segmentando o DataFrame Principal Segunda vez para construir os modelos
#df_novo = data_principal[["Date", "Close"]]
#df_novo.index.name = "id"
#df_novo = df_novo.rename(columns={"Date": "ds", "Close": "y"})
#df_novo.head()

#df_novo2.info()
#st.write('df_novo2')
#st.write(df_novo2.tail())
#--------------------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------------------
st.write('---------------------------------------------------------------------------------------------------')
# Remover MultiIndex para acessar colunas diretamente
df_novo2.columns = [col[1] if col[1] else col[0] for col in df_novo2.columns]
# Verificar as colunas
# Garantir que as colunas necessárias estejam presentes
colunas_necessarias = ['ds', 'y', 'unique_id']
# Filtrar datas de 6 meses
dt_inicial = '2024-03-19'
dt_final = '2024-09-19'
df_filtrado = df_novo2[(df_novo2['ds'] >= dt_inicial) & (df_novo2['ds'] <= dt_final)]
# Separar treino e validação
tamanho = int(len(df_filtrado) * 0.8)
treino = df_filtrado.iloc[:tamanho]
valid = df_filtrado.iloc[tamanho:]
h = valid['ds'].nunique()
# Treinando o modelo
model = StatsForecast(models=[Naive()], freq='D', n_jobs=-1)
model.fit(treino[['ds', 'unique_id', 'y']])
# Previsão
forecast_df = model.predict(h=h, level=[90])
forecast_df = forecast_df.reset_index().merge(valid[['ds', 'unique_id', 'y']], on=['ds', 'unique_id'], how='left').dropna()
# Métricas
y_true = forecast_df['y'].values
y_pred = forecast_df['Naive'].values
#-----------------------------------------------------------------------------------
#Altair NAIVE
import streamlit as st
import pandas as pd
import altair as alt
# Criar um app no Streamlit
st.title("Previsão com Modelo Naive")
# Criar DataFrame consolidado para Altair
df_treino = pd.DataFrame({'ds': treino['ds'], 'y': treino['y'], 'tipo': 'Treino'})
df_validacao = pd.DataFrame({'ds': forecast_df['ds'], 'y': forecast_df['y'], 'tipo': 'Validação (Real)'})
df_previsao = pd.DataFrame({'ds': forecast_df['ds'], 'y': forecast_df['Naive'], 'tipo': 'Previsão (Naive)'})
# Concatenar os DataFrames
df_total = pd.concat([df_treino, df_validacao, df_previsao])
# Criar gráfico com Altair
chart = alt.Chart(df_total).mark_line().encode(
    x='ds:T',
    y='y:Q',
    color='tipo:N',
    strokeDash=alt.condition(
        alt.datum.tipo == 'Previsão (Naive)',
        alt.value([5, 5]),  # Linhas tracejadas para previsão
        alt.value([0])       # Linhas normais para treino e validação
    )
).properties(
    width=800,
    height=400,
    title="Naive"
)
# Exibir no Streamlit
st.altair_chart(chart, use_container_width=True)
#-----------------------------------------------------------------------------------
def metricas(y_true, y_pred):
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    import numpy as np
    return {
        'MAE': mean_absolute_error(y_true, y_pred),
        'MSE': mean_squared_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred))
    }
resultado_metricas = metricas(y_true, y_pred)
for metric, value in resultado_metricas.items():
    st.write(f"{metric}: {value:.4f}")
# DataFrame para armazenar os resultados
resultados_modelos = pd.DataFrame(columns=['Modelo', 'WMAPE', 'MAE', 'MSE', 'RMSE', 'MAPE', 'SMAPE', 'MASE'])
def metricas(y_true, y_pred):
    """
    Calcula várias métricas de avaliação de séries temporais:
    WMAPE, MAE, MSE, RMSE, MAPE, SMAPE, MASE.

    Parâmetros:
    y_true: Valores reais.
    y_pred: Valores previstos.

    Retorno: Dicionário contendo as métricas calculadas.
    """
    # WMAPE  Erro Percentual Absoluto que avalia através de pesos
    wmape_value = np.abs(y_true - y_pred).sum() / np.abs(y_true).sum()

    # MAE - Média de Erro Absoluto
    mae = np.mean(np.abs(y_true - y_pred))

    # MSE - Erro quadrático médio
    mse = np.mean((y_true - y_pred)**2)

    # RMSE - Raiz quadrada do erro médio
    rmse = np.sqrt(mse)

    # MAPE - Erro absoluto percentual médio
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    # SMAPE - Erro absoluto médio em percentual simétrico
    smape = 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))

    # MASE - Erro médio de escala absoluto
    naive_forecast = np.roll(y_true, shift=1)  # Naive forecast (y_t-1)
    naive_forecast[0] = np.nan
    mase = np.mean(np.abs(y_true[1:] - y_pred[1:])) / np.mean(np.abs(y_true[1:] - naive_forecast[1:]))


    return {
        'WMAPE': wmape_value,
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'MAPE': mape,
        'SMAPE': smape,
        'MASE': mase
    }
#-----------------------------------------------------------------------------------
st.title("Previsão com Modelo SeasonalNaive")
# n_jobs -1 parâmetro padrão, para utilizar as CPUS
# season_length=5 Dias úteis na semana
model_s = StatsForecast(models=[SeasonalNaive(season_length=21)], freq='D', n_jobs=-1)
model_s.fit(treino)
# Convertendo para datetime o índice
valid['ds'] = pd.to_datetime(valid['ds'])
forecast_dfs = model_s.predict(h=h, level=[90])
forecast_dfs = forecast_dfs.reset_index().merge(valid, on=['ds', 'unique_id'], how='left').dropna()
# Remover a coluna 'index' do DataFrame
forecast_dfs = forecast_dfs.drop(columns=['index'])
#forecast_dfs.head()
#plt.figure(figsize=(12, 8))
#model_s.plot(treino, forecast_dfs, level=[90], unique_ids=[ticker],  engine ='matplotlib', max_insample_length=90)
# Criar DataFrame consolidado para Altair
df_treino = pd.DataFrame({'ds': treino['ds'], 'y': treino['y'], 'tipo': 'Treino'})
df_validacao = pd.DataFrame({'ds': forecast_dfs['ds'], 'y': forecast_dfs['y'], 'tipo': 'Validação (Real)'})
df_previsao = pd.DataFrame({'ds': forecast_dfs['ds'], 'y': forecast_dfs['SeasonalNaive'], 'tipo': 'Previsão (SeasonalNaive)'})
# Concatenar os DataFrames
df_total = pd.concat([df_treino, df_validacao, df_previsao])
# Criar gráfico com Altair
chart = alt.Chart(df_total).mark_line().encode(
    x='ds:T',
    y='y:Q',
    color='tipo:N',
    strokeDash=alt.condition(
        alt.datum.tipo == 'Previsão (SeasonalNaive)',
        alt.value([5, 5]),  # Linhas tracejadas para previsão
        alt.value([0])       # Linhas normais para treino e validação
    )
).properties(
    width=800,
    height=400,
    title="SeasonalNaive"
)
# Exibir no Streamlit
st.altair_chart(chart, use_container_width=True)
#
resultado_metricas = metricas(forecast_dfs['y'].values,  forecast_dfs['SeasonalNaive'].values )
for metric, value in resultado_metricas.items():
    st.write(f"{metric}: {value:.4f}")

modelo = 'SeasonalNaive'
novo_resultado = pd.DataFrame([{'Modelo': modelo, **resultado_metricas}])
resultados_modelos = pd.concat([resultados_modelos, novo_resultado], ignore_index=True)
#-----------------------------------------------------------
st.title("Previsão com SeasonalWindowAverage")
"""**Utilizando o modelo com Média Móvel com Sazonalidade o SeasonalWindowAverage.**"""
# n_jobs -1 parâmetro padrão, para utilizar as CPUS
# Adicionado o parâmetro window_size que são as janelas, posso usar 2 para pegar a média das 2 últimas semanas
# season_length=5 , utilizado 5 dias úteis na semana
model_sm = StatsForecast(models=[SeasonalWindowAverage(season_length=5, window_size=2, prediction_intervals=ConformalIntervals(h=h, n_windows=2))], freq='D', n_jobs=-1)
model_sm.fit(treino)
#  Convertendo para datetime o índice
valid['ds'] = pd.to_datetime(valid['ds'])

forecast_dfsm = model_sm.predict(h=h, level=[90])
forecast_dfsm = forecast_dfsm.reset_index().merge(valid, on=['ds', 'unique_id'], how='left').dropna()
# Remover a coluna 'index' do DataFrame
forecast_dfsm = forecast_dfsm.drop(columns=['index'])
#forecast_dfsm.head()

# Criar DataFrame consolidado para Altair
df_treino = pd.DataFrame({'ds': treino['ds'], 'y': treino['y'], 'tipo': 'Treino'})
df_validacao = pd.DataFrame({'ds': forecast_dfsm['ds'], 'y': forecast_dfsm['y'], 'tipo': 'Validação (Real)'})
df_previsao = pd.DataFrame({'ds': forecast_dfsm['ds'], 'y': forecast_dfsm['SeasWA'], 'tipo': 'Previsão (SeasWA)'})
# Concatenar os DataFrames
df_total = pd.concat([df_treino, df_validacao, df_previsao])
# Criar gráfico com Altair
chart = alt.Chart(df_total).mark_line().encode(
    x='ds:T',
    y='y:Q',
    color='tipo:N',
    strokeDash=alt.condition(
        alt.datum.tipo == 'Previsão (SeasWA)',
        alt.value([5, 5]),  # Linhas tracejadas para previsão
        alt.value([0])       # Linhas normais para treino e validação
    )
).properties(
    width=800,
    height=400,
    title="SeasWA"
)
# Exibir no Streamlit
st.altair_chart(chart, use_container_width=True)

resultado_metricas = metricas(forecast_dfsm['y'].values,  forecast_dfsm['SeasWA'].values )
for metric, value in resultado_metricas.items():
    st.write(f"{metric}: {value:.4f}")
modelo = 'SeasWA'
novo_resultado = pd.DataFrame([{'Modelo': modelo, **resultado_metricas}])
resultados_modelos = pd.concat([resultados_modelos, novo_resultado], ignore_index=True)

#plt.figure(figsize=(12, 8))
#model_sm.plot(treino, forecast_dfsm, level=[90], unique_ids=[ticker],  engine ='matplotlib', max_insample_length=90)

#forecast_dfsm
#------------------------------------------------------------------------------------------------------
st.title("Previsão com AUTOARIMA")
"""**Utilizando o modelo AUTOARIMA, olha o fechamento no passado e encontra uma correlação futura, semelhante ao modelo Base Line Naive.**"""

#ARIMA
#(AR) : Autoregressivo, I: Integrado, MA: Média Móvel

#A(x,y,z) => ACF, PACF
# Determinando o valor de x

# Considera 3 pontos:
# Modelo Autoregressivo
# Modelo Integrado
# Média Móvel
# I - quantidade que a série foi diferenciada
model_a = StatsForecast(models=[AutoARIMA(season_length=5)], freq='D', n_jobs=-1)
model_a.fit(treino)
valid['ds'] = pd.to_datetime(valid['ds'])
forecast_dfa = model_a.predict(h=h, level=[90])
forecast_dfa = forecast_dfa.reset_index().merge(valid, on=['ds', 'unique_id'], how='left').dropna()
# Remover a coluna 'index' do DataFrame
forecast_dfa = forecast_dfa.drop(columns=['index'])
#forecast_dfa.head()
# Criar DataFrame consolidado para Altair
df_treino = pd.DataFrame({'ds': treino['ds'], 'y': treino['y'], 'tipo': 'Treino'})
df_validacao = pd.DataFrame({'ds': forecast_dfa['ds'], 'y': forecast_dfa['y'], 'tipo': 'Validação (Real)'})
df_previsao = pd.DataFrame({'ds': forecast_dfa['ds'], 'y': forecast_dfa['AutoARIMA'], 'tipo': 'Previsão (AutoARIMA)'})
# Concatenar os DataFrames
df_total = pd.concat([df_treino, df_validacao, df_previsao])
# Criar gráfico com Altair
chart = alt.Chart(df_total).mark_line().encode(
    x='ds:T',
    y='y:Q',
    color='tipo:N',
    strokeDash=alt.condition(
        alt.datum.tipo == 'Previsão (AutoARIMA)',
        alt.value([5, 5]),  # Linhas tracejadas para previsão
        alt.value([0])       # Linhas normais para treino e validação
    )
).properties(
    width=800,
    height=400,
    title="AutoARIMA"
)
# Exibir no Streamlit
st.altair_chart(chart, use_container_width=True)
#
resultado_metricas = metricas(forecast_dfa['y'].values,  forecast_dfa['AutoARIMA'].values )
for metric, value in resultado_metricas.items():
    st.write(f"{metric}: {value:.4f}")

modelo = 'AutoARIMA'
novo_resultado = pd.DataFrame([{'Modelo': modelo, **resultado_metricas}])
resultados_modelos = pd.concat([resultados_modelos, novo_resultado], ignore_index=True)
#plt.figure(figsize=(12, 8))
#model_a.plot(treino, forecast_dfa, level=[90], unique_ids=[ticker],  engine ='matplotlib', max_insample_length=90)
#---------------------------------------------------------------------------------
"""**Utilizando o Modelo PROPHET**"""
# Criando o app no Streamlit
st.title("Prophet")
df_prophet = df_filtrado
# Ajustar / Treinar o modelo
model_prophet = Prophet(daily_seasonality=True)
model_prophet.fit(df_prophet)

# freq='B' somente dias úteis
future = model_prophet.make_future_dataframe(periods=5, freq='B')
forecast_prophet = model_prophet.predict(future)
# Merge para combinar valores reais e predições
df_merged = pd.merge(df_prophet, forecast_prophet[['ds', 'yhat']], on='ds', how='inner')

# Criar DataFrame consolidado para Altair
df_real = pd.DataFrame({'ds': df_prophet['ds'], 'y': df_prophet['y'], 'tipo': 'Valores Reais'})
df_previsao = pd.DataFrame({'ds': forecast_prophet['ds'], 'y': forecast_prophet['yhat'], 'tipo': 'Previsão Prophet'})
df_incerteza = pd.DataFrame({
    'ds': forecast_prophet['ds'],
    'yhat_lower': forecast_prophet['yhat_lower'],
    'yhat_upper': forecast_prophet['yhat_upper']
})

# Concatenar os DataFrames para um gráfico único
df_total = pd.concat([df_real, df_previsao])

# Criar gráfico de linha para os valores reais e previsão
chart = alt.Chart(df_total).mark_line().encode(
    x='ds:T',
    y='y:Q',
    color='tipo:N'
).properties(
    width=800,
    height=400,
    title="Previsão usando Prophet"
)

# Criar a faixa de incerteza (área sombreada)
band = alt.Chart(df_incerteza).mark_area(opacity=0.3, color="green").encode(
    x='ds:T',
    y='yhat_lower:Q',
    y2='yhat_upper:Q'
)

# Exibir no Streamlit
st.altair_chart(band + chart, use_container_width=True)

resultado_metricas = metricas(df_merged['y'].values,  df_merged['yhat'].values )
for metric, value in resultado_metricas.items():
    st.write(f"{metric}: {value:.4f}")

modelo = 'Prophet'
novo_resultado = pd.DataFrame([{'Modelo': modelo, **resultado_metricas}])
resultados_modelos = pd.concat([resultados_modelos, novo_resultado], ignore_index=True)
#--------------------------------------------------------------------------------------------
# Criando o app no Streamlit
st.title("Previsões do XGBoost vs. Valores Reais")

"""**Utilizando o Modelo XGBOOST**"""
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import matplotlib.dates as mdates
import altair as alt

df_xgb = df_filtrado
df_xgb['ds'] = pd.to_datetime(df_xgb['ds'])

# Extraindo características temporais, como ano, mês e dia para o modelo XGBoost
df_xgb['ano'] = df_xgb['ds'].dt.year
df_xgb['mes'] = df_xgb['ds'].dt.month
df_xgb['dia'] = df_xgb['ds'].dt.day
df_xgb['diadasemana'] = df_xgb['ds'].dt.dayofweek

# Definindo as features X e o alvo y
X = df_xgb[['ano', 'mes', 'dia']]  # Features baseadas em 'ds'
y = df_xgb['y']  # Target, a coluna de valores que queremos prever

# Dividindo os dados entre treino e validação (80% treino, 20% validação)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)

# Inicializando o modelo XGBoost Regressor
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000)

# Treinando o modelo
xgb_model.fit(X_train, y_train)

# Fazendo previsões para os dados de validação
y_pred = xgb_model.predict(X_valid)
# Criar DataFrame consolidado para Altair
df_real = pd.DataFrame({
    'ds': df_xgb['ds'].iloc[len(X_train):],
    'y': y_valid,
    'tipo': 'Valores Reais'
})

df_previsao = pd.DataFrame({
    'ds': df_xgb['ds'].iloc[len(X_train):],
    'y': y_pred,
    'tipo': 'Previsões XGBoost'
})

# Concatenar os DataFrames
df_total = pd.concat([df_real, df_previsao])

# Criar gráfico de linha para os valores reais e previsão
chart = alt.Chart(df_total).mark_line().encode(
    x=alt.X('ds:T', axis=alt.Axis(title='Data', format='%Y-%m-%d')),
    y=alt.Y('y:Q', axis=alt.Axis(title='Valores')),
    color='tipo:N'
).properties(
    width=800,
    height=400,
    title="Previsões do XGBoost vs. Valores Reais"
)

# Exibir no Streamlit
st.altair_chart(chart, use_container_width=True)

resultado_metricas = metricas(y_valid.values,  y_pred )
for metric, value in resultado_metricas.items():
    st.write(f"{metric}: {value:.4f}")

modelo = 'XGBoost'
novo_resultado = pd.DataFrame([{'Modelo': modelo, **resultado_metricas}])
resultados_modelos = pd.concat([resultados_modelos, novo_resultado], ignore_index=True)
# Plotando os resultados
plt.figure(figsize=(12,8))
plt.plot(df_xgb['ds'].iloc[len(X_train):], y_valid, label='Valores Reais', color='blue')
plt.plot(df_xgb['ds'].iloc[len(X_train):], y_pred, label='Previsões XGBoost', color='red', linestyle='--')
plt.xlabel('Data')
plt.ylabel('Valores')
plt.title('Previsões do XGBoost vs. Valores Reais')
plt.legend()
# Ajustando a rotação dos rótulos de data no eixo x
plt.xticks(rotation=45)
# Opcional: formatando as datas
ax = plt.gca()
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
# Ajuste de layout para evitar corte de rótulos
plt.tight_layout()
plt.show()


st.title("Resultado dos Modelos")
st.write(resultados_modelos)


